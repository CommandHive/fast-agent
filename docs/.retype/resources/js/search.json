[[{"l":"README"},{"l":"Overview","p":["This is agent orchestrator backend to create agents on fly, store all your MCP variables and get tasks done round the clock from these agents. Visit CommandHive Website"]},{"l":"✅ Completed","p":["Ensure sampling as MCP feature is working","Create Pub/Sub support using Redis","Create Pub/Sub support using Kafka","Create Pub/Sub support using MSK (Managed Kafka)","Ensure tool calling is done with confirmation","Check compatibility with Python 3.11","Check compatibility with Python 3.12"]},{"l":"⏳ To Do Next","p":["Integrate smart contract for tool calling","Each agent has its own wallet (defined in config)","Pub/Sub support for RabbitMQ","Pub/Sub support for Google Pub/Sub"]}],[{"l":"Config"},{"l":"Configuration"},{"l":"Sub-Agents","p":["Define a list of sub-agent dicts in agent.py. Each entry needs:","name: Unique identifier (e.g., finder).","instruction: Prompt for that agent’s behavior.","servers: MCP server names this agent can call (e.g., [fetch,brave]).","model: LLM model identifier (e.g., haiku).","Example:"]},{"l":"MCP Settings","p":["In agent.py, include a JSON config dict (here called sample_json_config) to specify:","mcp.servers: Each server’s name, transport, command, args, and any env vars.","default_model: Fallback LLM (e.g., haiku).","logger: level(e.g., info) and type( console).","pubsub_enabled: True to use Redis.","pubsub_config.redis:","host: e.g., localhost","port: 6379","db: 0","channel_prefix: agent:","anthropic.api_key: Loaded from os.environ.get(CLAUDE_API_KEY, ).","A minimal example:"]},{"l":"agent.py Overview","p":["agent.py sets up a Queen Agent named queen and dynamically registers sub-agents defined in subagents_config. The main steps are:","Load .env(via dotenv).","Instantiate FastAgent(name=queen, json_config=sample_json_config).","Dynamically decorate each sub-agent(looping over subagents_config) with @fast.agent(name=..., instruction=..., servers=..., model=...).","Define an orchestrator with @fast.orchestrator(name=orchestrate, agents=[...], plan_type=full, model=haiku).","In main(), create an async Redis client, subscribe to agent:queen, send an initial task to agent.orchestrate(...), and then loop reading Redis messages. For each message:","Decode JSON; if it has type == user, forward content to agent.orchestrate(user_input).","If JSON decoding fails, pass raw text to agent.orchestrate(text).","Run with:","Key Points","The channel used is agent:queen.","Sub-agent names in @fast.orchestrator(agents=[...]) must match those registered via @fast.agent(...).","Redis Pub/Sub handles message delivery."]}],[{"l":"Listener"},{"l":"listener.py Overview","p":["listener.py is a simple script to debug incoming messages on the same Redis channel:","Purpose: Print every raw message published to agent:queen.","Run with:"]},{"l":"Usage","p":["Ensure Redis is running on localhost:6379.","Activate your virtual environment:","Run the Queen Agent:","Optionally, run the listener(for debugging):","Publish a test message(via redis-cli):"]}],[{"l":"Quickstart"},{"l":"Introduction","p":["Bee Agent( bee_agent) is a Python framework for building AI “Queen” and “Worker” sub-agents that communicate via Redis Pub/Sub and use Model Context Protocol (MCP) servers (e.g., Brave Search, fetch). You can dynamically register multiple sub-agents, each with its own prompt instructions and tooling access."]},{"l":"Quickstart Guide","p":["Start Redis","Create & activate a virtual environment","Install bee_agent","Set environment variables","Run the Queen Agent","(Optional) Run the listener","Test via Redis CLI"]},{"l":"Installation","p":["Ensure Redis is running on localhost:6379."]},{"l":"Environment Variables","p":["Create a file named .env in the project root:","These are required for any Anthropic-based models or internal agent authentication."]}]]